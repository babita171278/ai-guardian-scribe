{"openapi":"3.1.0","info":{"title":"LLM Evaluation & Guardrail API","description":"An API for evaluating Large Language Models on various metrics and applying guardrails.","version":"0.1.0"},"paths":{"/deepeval/answer-relevancy":{"post":{"tags":["DeepEval Metrics"],"summary":"Evaluate Answer Relevancy","description":"Evaluates how relevant an AI's answer is to the user's question.","operationId":"evaluate_answer_relevancy_deepeval_answer_relevancy_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/AnswerRelevancyRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/AnswerRelevancyResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/deepeval/bias":{"post":{"tags":["DeepEval Metrics"],"summary":"Evaluate Bias","description":"Evaluates the presence of bias in an AI's output, optionally using the user's\noriginal input for better contextual evaluation.","operationId":"evaluate_bias_deepeval_bias_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/BiasRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/BiasEvaluationResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/deepeval/faithfulness":{"post":{"tags":["DeepEval Metrics"],"summary":"Evaluate Faithfulness","description":"Evaluates if an AI's output is faithful to the provided context.\nThe user's original input can be provided for more nuanced evaluation.","operationId":"evaluate_faithfulness_deepeval_faithfulness_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/FaithfulnessRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/FaithfulnessEvaluationResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/deepeval/hallucination":{"post":{"tags":["DeepEval Metrics"],"summary":"Evaluate Hallucination","description":"Evaluates if an AI's output contains hallucinations based on provided contexts.\nThe user's original input can be provided for more nuanced evaluation.","operationId":"evaluate_hallucination_deepeval_hallucination_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/deepeval_eval__deepeval_api__HallucinationRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HallucinationEvaluationResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/deepeval/pii-leakage":{"post":{"tags":["DeepEval Metrics"],"summary":"Evaluate PII Leakage","description":"Evaluates if an AI's output leaks any Personally Identifiable Information (PII).","operationId":"evaluate_pii_leakage_deepeval_pii_leakage_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/PiiLeakageRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/PIILeakageEvaluationResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/deepeval/toxicity":{"post":{"tags":["DeepEval Metrics"],"summary":"Evaluate Toxicity","description":"Evaluates the toxicity level of an AI's output.","operationId":"evaluate_toxicity_deepeval_toxicity_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ToxicityRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ToxicityEvaluationResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/cybersecurity/scan-input":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Input for Cybersecurity Threats","description":"Checks user input for common cybersecurity attack patterns like SQL injection, shell injection, etc.","operationId":"scan_cybersecurity_input_guardrail_cybersecurity_scan_input_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/CybersecurityInputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/CybersecurityInputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/cybersecurity/scan-output":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Output for Cybersecurity Vulnerabilities","description":"Checks AI output for leaked credentials, attack code, or other vulnerabilities.","operationId":"scan_cybersecurity_output_guardrail_cybersecurity_scan_output_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/CybersecurityOutputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/CybersecurityOutputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/illegal/scan-input":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Input for Illegal Activity Requests","description":"Checks user input for requests related to illegal activities (e.g., asking how to make a bomb).","operationId":"scan_illegal_input_guardrail_illegal_scan_input_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/IllegalInputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/IllegalInputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/illegal/scan-output":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Output for Facilitating Illegal Activities","description":"Checks if the AI's response provides instructions or information that facilitates illegal acts.","operationId":"scan_illegal_output_guardrail_illegal_scan_output_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/IllegalOutputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/IllegalOutputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/privacy/scan-input":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Input for PII","description":"Checks user input for Personally Identifiable Information (PII) like names, emails, or phone numbers.","operationId":"scan_privacy_input_guardrail_privacy_scan_input_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/PrivacyInputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/PrivacyInputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/privacy/scan-output":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Output for PII","description":"Checks if the AI's response leaks any Personally Identifiable Information (PII).","operationId":"scan_privacy_output_guardrail_privacy_scan_output_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/PrivacyOutputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/PrivacyOutputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/prompt-injection/scan-input":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Input for Prompt Injection","description":"Checks user input for attempts to manipulate or 'jailbreak' the language model.","operationId":"scan_prompt_injection_input_guardrail_prompt_injection_scan_input_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/PromptInjectionInputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/PromptInjectionInputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/prompt-injection/scan-output":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Output for Successful Prompt Injection","description":"Checks if the AI's response indicates that a prompt injection attack was successful.","operationId":"scan_prompt_injection_output_guardrail_prompt_injection_scan_output_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/PromptInjectionOutputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/PromptInjectionOutputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/toxicity/scan-input":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Input for Toxicity","description":"Checks user input for toxic content like hate speech, insults, or profanity.","operationId":"scan_toxicity_input_guardrail_toxicity_scan_input_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ToxicityInputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ToxicityInputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/toxicity/scan-output":{"post":{"tags":["Guardrail Checks"],"summary":"Scan Output for Toxicity","description":"Checks if the AI's response contains toxic content.","operationId":"scan_toxicity_output_guardrail_toxicity_scan_output_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ToxicityOutputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ToxicityOutputResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/guardrail/chat/gemini":{"post":{"tags":["Guardrail Checks"],"summary":"Chat with Gemini","description":"Receives user input, sends it to the Gemini model using Langchain,\nand returns the model's response.","operationId":"chat_with_gemini_guardrail_chat_gemini_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ChatInputRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/opikeval/answer-relevance":{"post":{"tags":["OpikEval Metrics"],"summary":"Evaluate Answer Relevance","description":"Evaluates how relevant an AI's answer is to the user's question, with optional context.","operationId":"evaluate_answer_relevance_opikeval_answer_relevance_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/AnswerRelevanceRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/AnswerRelevanceResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/opikeval/context-precision":{"post":{"tags":["OpikEval Metrics"],"summary":"Evaluate Context Precision","description":"Evaluates how precisely an AI's answer aligns with the expected answer, given the context.","operationId":"evaluate_context_precision_opikeval_context_precision_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ContextPrecisionRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ContextPrecisionResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/opikeval/context-recall":{"post":{"tags":["OpikEval Metrics"],"summary":"Evaluate Context Recall","description":"Evaluates how well an AI's response recalls and utilizes information from the provided context.","operationId":"evaluate_context_recall_opikeval_context_recall_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ContextRecallRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ContextRecallResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/opikeval/hallucination":{"post":{"tags":["OpikEval Metrics"],"summary":"Evaluate Hallucination","description":"Evaluates if an AI's output contains hallucinations (information not supported by the context).","operationId":"evaluate_hallucination_opikeval_hallucination_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/opik_eval__opic_eval_api__HallucinationRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HallucinationResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/opikeval/moderation":{"post":{"tags":["OpikEval Metrics"],"summary":"Moderate Text Content","description":"Moderates a piece of text for safety issues like toxicity, hate speech, etc.","operationId":"moderate_content_opikeval_moderation_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ModerationRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ModerationResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/opikeval/usefulness":{"post":{"tags":["OpikEval Metrics"],"summary":"Evaluate Usefulness","description":"Evaluates the overall usefulness of an AI's response to a user's question.","operationId":"evaluate_usefulness_opikeval_usefulness_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/UsefulnessRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/UsefulnessResult"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/":{"get":{"tags":["Root"],"summary":"Read Root","description":"A simple root endpoint to confirm that the API is running correctly.","operationId":"read_root__get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}}},"components":{"schemas":{"AnswerRelevanceRequest":{"properties":{"user_input":{"type":"string","title":"User Input","description":"The user's original question or prompt."},"ai_output":{"type":"string","title":"Ai Output","description":"The AI's response to be evaluated."},"context":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Context","description":"Optional context for the evaluation."},"sensitivity":{"$ref":"#/components/schemas/opik_eval__answer_relevance__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["user_input","ai_output"],"title":"AnswerRelevanceRequest"},"AnswerRelevanceResult":{"properties":{"answer_relevance_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Answer Relevance Score","description":"Answer relevance score between 0.0 and 1.0"},"relevancy_level":{"$ref":"#/components/schemas/RelevancyLevel","description":"Categorical relevancy level: excellent, good, fair, or poor"},"reason":{"type":"string","minLength":20,"title":"Reason","description":"Brief explanation of the score based on evaluation criteria"},"sensitivity_level":{"$ref":"#/components/schemas/opik_eval__answer_relevance__SensitivityLevel","description":"Sensitivity level used for evaluation"}},"type":"object","required":["answer_relevance_score","relevancy_level","reason","sensitivity_level"],"title":"AnswerRelevanceResult","description":"Pydantic model for answer relevance evaluation results with validation."},"AnswerRelevancyRequest":{"properties":{"user_input":{"type":"string","title":"User Input","description":"The user's original question or prompt."},"ai_output":{"type":"string","title":"Ai Output","description":"The AI's response to be evaluated."},"sensitivity":{"$ref":"#/components/schemas/deepeval_eval__answer_relevancy__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["user_input","ai_output"],"title":"AnswerRelevancyRequest"},"AnswerRelevancyResult":{"properties":{"relevancy_level":{"$ref":"#/components/schemas/RelevancyLevel","description":"Categorical relevancy level: excellent, good, fair, or poor"},"relevancy_percentage":{"type":"number","maximum":100.0,"minimum":0.0,"title":"Relevancy Percentage","description":"Percentage of relevant statements (0.0 to 100.0)"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the relevancy level"},"statements":{"items":{"type":"string"},"type":"array","title":"Statements","description":"Statements extracted from the output"},"verdicts":{"items":{"$ref":"#/components/schemas/VerdictItem"},"type":"array","title":"Verdicts","description":"Verdicts for each statement"},"relevant_statements_count":{"type":"integer","title":"Relevant Statements Count","description":"Number of relevant statements"},"total_statements_count":{"type":"integer","title":"Total Statements Count","description":"Total number of statements"},"sensitivity_level":{"$ref":"#/components/schemas/deepeval_eval__answer_relevancy__SensitivityLevel","description":"Sensitivity level used for evaluation"}},"type":"object","required":["relevancy_level","relevancy_percentage","reason","statements","verdicts","relevant_statements_count","total_statements_count","sensitivity_level"],"title":"AnswerRelevancyResult","description":"Pydantic model for complete answer relevancy evaluation results."},"BiasEvaluationResult":{"properties":{"bias_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Bias Score","description":"Bias score between 0.0 and 1.0 (lower is better)"},"bias_level":{"type":"string","title":"Bias Level","description":"Categorical bias level (excellent, good, fair, poor)"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the score"},"opinions":{"items":{"type":"string"},"type":"array","title":"Opinions","description":"Opinions extracted from the output"},"verdicts":{"items":{"$ref":"#/components/schemas/BiasVerdictItem"},"type":"array","title":"Verdicts","description":"Bias verdicts for each opinion"},"biased_opinions_count":{"type":"integer","title":"Biased Opinions Count","description":"Number of biased opinions"},"total_opinions_count":{"type":"integer","title":"Total Opinions Count","description":"Total number of opinions"}},"type":"object","required":["bias_score","bias_level","reason","opinions","verdicts","biased_opinions_count","total_opinions_count"],"title":"BiasEvaluationResult","description":"Pydantic model for complete bias evaluation results."},"BiasRequest":{"properties":{"ai_output":{"type":"string","title":"Ai Output","description":"The AI's response to be evaluated for bias."},"user_input":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"User Input","description":"The user's original question for contextual evaluation."}},"type":"object","required":["ai_output"],"title":"BiasRequest"},"BiasVerdictItem":{"properties":{"verdict":{"type":"string","pattern":"^(yes|no)$","title":"Verdict","description":"Verdict: 'yes' or 'no'"},"reason":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Reason","description":"Reason for the verdict (required only for 'yes' verdicts)"}},"type":"object","required":["verdict"],"title":"BiasVerdictItem","description":"Pydantic model for individual bias verdict items."},"ChatInputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The user input for the chat."}},"type":"object","required":["input_text"],"title":"ChatInputRequest"},"ContextPrecisionRequest":{"properties":{"user_input":{"type":"string","title":"User Input","description":"The user's original question or prompt."},"ai_output":{"type":"string","title":"Ai Output","description":"The AI's response to be evaluated."},"expected_output":{"type":"string","title":"Expected Output","description":"The ideal or ground-truth answer."},"context":{"type":"string","title":"Context","description":"The context provided to the AI."},"sensitivity":{"$ref":"#/components/schemas/opik_eval__context_precision__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["user_input","ai_output","expected_output","context"],"title":"ContextPrecisionRequest"},"ContextPrecisionResult":{"properties":{"context_precision_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Context Precision Score","description":"Context precision score between 0.0 and 1.0"},"precision_level":{"$ref":"#/components/schemas/PrecisionLevel","description":"Categorical precision level: excellent, good, fair, or poor"},"reason":{"type":"string","minLength":20,"title":"Reason","description":"Detailed explanation of the score based on evaluation criteria"},"sensitivity_level":{"$ref":"#/components/schemas/opik_eval__context_precision__SensitivityLevel","description":"Sensitivity level used for evaluation"}},"type":"object","required":["context_precision_score","precision_level","reason","sensitivity_level"],"title":"ContextPrecisionResult","description":"Pydantic model for context precision evaluation results with validation."},"ContextRecallRequest":{"properties":{"user_input":{"type":"string","title":"User Input","description":"The user's original question or prompt."},"ai_output":{"type":"string","title":"Ai Output","description":"The AI's response to be evaluated."},"expected_output":{"type":"string","title":"Expected Output","description":"The ideal or ground-truth answer."},"context":{"type":"string","title":"Context","description":"The context that the AI should have recalled."},"sensitivity":{"$ref":"#/components/schemas/opik_eval__context_recall__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["user_input","ai_output","expected_output","context"],"title":"ContextRecallRequest"},"ContextRecallResult":{"properties":{"context_recall_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Context Recall Score","description":"Context recall score between 0.0 and 1.0"},"recall_level":{"$ref":"#/components/schemas/RecallLevel","description":"Categorical recall level: excellent, good, fair, or poor"},"reason":{"type":"string","minLength":20,"title":"Reason","description":"Detailed explanation of the score based on evaluation criteria"},"sensitivity_level":{"$ref":"#/components/schemas/opik_eval__context_recall__SensitivityLevel","description":"Sensitivity level used for evaluation"}},"type":"object","required":["context_recall_score","recall_level","reason","sensitivity_level"],"title":"ContextRecallResult","description":"Pydantic model for context recall evaluation results with validation."},"CybersecurityInputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The user input to analyze for security threats."},"categories":{"items":{"type":"string"},"type":"array","title":"Categories","description":"List of security categories to check.","example":["SQL injection","Shell injection"]},"sensitivity":{"$ref":"#/components/schemas/guardrail__cyber_security_guard__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"},"purpose":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Purpose","description":"Optional application purpose to provide context for the evaluation."}},"type":"object","required":["input_text","categories"],"title":"CybersecurityInputRequest"},"CybersecurityInputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|uncertain)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'uncertain'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the security assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text that was analyzed"},"categories":{"items":{"type":"string"},"type":"array","title":"Categories","description":"The security categories that were checked"},"threats_detected":{"items":{"type":"string"},"type":"array","title":"Threats Detected","description":"Specific threats or attack patterns detected","default":[]},"purpose":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Purpose","description":"The application purpose context"},"sensitivity_level":{"$ref":"#/components/schemas/guardrail__cyber_security_guard__SensitivityLevel","description":"Sensitivity level used for evaluation"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0},"confidence":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Confidence","description":"Confidence level in assessment (0.0-1.0)","default":0.8}},"type":"object","required":["safety_level","reason","input_text","categories","sensitivity_level"],"title":"CybersecurityInputResult","description":"Pydantic model for input cybersecurity detection results."},"CybersecurityOutputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The original user input that prompted the AI's response."},"output_text":{"type":"string","title":"Output Text","description":"The AI's response to analyze for security vulnerabilities."},"categories":{"items":{"type":"string"},"type":"array","title":"Categories","description":"List of security categories to check.","example":["SQL injection","Information Disclosure"]},"sensitivity":{"$ref":"#/components/schemas/guardrail__cyber_security_guard__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"},"purpose":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Purpose","description":"Optional application purpose to provide context for the evaluation."}},"type":"object","required":["input_text","output_text","categories"],"title":"CybersecurityOutputRequest"},"CybersecurityOutputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|uncertain)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'uncertain'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the security assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text"},"output_text":{"type":"string","title":"Output Text","description":"The AI output that was analyzed"},"categories":{"items":{"type":"string"},"type":"array","title":"Categories","description":"The security categories that were checked"},"threats_detected":{"items":{"type":"string"},"type":"array","title":"Threats Detected","description":"Specific threats or attack patterns detected","default":[]},"purpose":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Purpose","description":"The application purpose context"},"sensitivity_level":{"$ref":"#/components/schemas/guardrail__cyber_security_guard__SensitivityLevel","description":"Sensitivity level used for evaluation"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0},"confidence":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Confidence","description":"Confidence level in assessment (0.0-1.0)","default":0.8}},"type":"object","required":["safety_level","reason","input_text","output_text","categories","sensitivity_level"],"title":"CybersecurityOutputResult","description":"Pydantic model for output cybersecurity detection results."},"FaithfulnessEvaluationResult":{"properties":{"faithfulness_level":{"$ref":"#/components/schemas/FaithfulnessLevel","description":"Categorical faithfulness level: excellent, good, fair, or poor"},"faithfulness_percentage":{"type":"number","maximum":100.0,"minimum":0.0,"title":"Faithfulness Percentage","description":"Percentage of faithful claims (0.0 to 100.0)"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the faithfulness level"},"truths":{"items":{"type":"string"},"type":"array","title":"Truths","description":"Truths extracted from retrieval context"},"claims":{"items":{"type":"string"},"type":"array","title":"Claims","description":"Claims extracted from actual output"},"verdicts":{"items":{"$ref":"#/components/schemas/FaithfulnessVerdictItem"},"type":"array","title":"Verdicts","description":"Faithfulness verdicts for each claim"},"contradictions_count":{"type":"integer","title":"Contradictions Count","description":"Number of contradictions found"},"total_claims_count":{"type":"integer","title":"Total Claims Count","description":"Total number of claims analyzed"},"sensitivity_level":{"$ref":"#/components/schemas/deepeval_eval__faithfulness__SensitivityLevel","description":"Sensitivity level used for evaluation"}},"type":"object","required":["faithfulness_level","faithfulness_percentage","reason","truths","claims","verdicts","contradictions_count","total_claims_count","sensitivity_level"],"title":"FaithfulnessEvaluationResult","description":"Pydantic model for complete faithfulness evaluation results."},"FaithfulnessLevel":{"type":"string","enum":["excellent","good","fair","poor"],"title":"FaithfulnessLevel","description":"Enum for the 4-level categorical faithfulness scoring."},"FaithfulnessRequest":{"properties":{"actual_output":{"type":"string","title":"Actual Output","description":"The AI's response to be evaluated."},"retrieval_context":{"type":"string","title":"Retrieval Context","description":"The context that the AI's response should be faithful to."},"user_input":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"User Input","description":"The user's original question for contextual evaluation."},"sensitivity":{"$ref":"#/components/schemas/deepeval_eval__answer_relevancy__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["actual_output","retrieval_context"],"title":"FaithfulnessRequest"},"FaithfulnessVerdictItem":{"properties":{"verdict":{"type":"string","pattern":"^(yes|no|idk)$","title":"Verdict","description":"Verdict: 'yes', 'no', or 'idk'"},"reason":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Reason","description":"Reason for the verdict (required only for 'no' verdicts)"}},"type":"object","required":["verdict"],"title":"FaithfulnessVerdictItem","description":"Pydantic model for individual faithfulness verdict items."},"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"HallucinationEvaluationResult":{"properties":{"hallucination_level":{"$ref":"#/components/schemas/HallucinationLevel","description":"Categorical hallucination level: excellent, good, fair, or poor"},"hallucination_percentage":{"type":"number","maximum":100.0,"minimum":0.0,"title":"Hallucination Percentage","description":"Percentage of contradictory contexts (0.0 to 100.0)"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the hallucination level"},"contexts":{"items":{"type":"string"},"type":"array","title":"Contexts","description":"Contexts used for evaluation"},"verdicts":{"items":{"$ref":"#/components/schemas/HallucinationVerdictItem"},"type":"array","title":"Verdicts","description":"Verdicts for each context"},"contradictions_count":{"type":"integer","title":"Contradictions Count","description":"Number of contradictions found"},"total_contexts_count":{"type":"integer","title":"Total Contexts Count","description":"Total number of contexts"},"sensitivity_level":{"$ref":"#/components/schemas/deepeval_eval__hallucination__SensitivityLevel","description":"Sensitivity level used for evaluation"},"factual_alignments":{"items":{"type":"string"},"type":"array","title":"Factual Alignments","description":"List of factual alignments found","default":[]},"contradictions":{"items":{"type":"string"},"type":"array","title":"Contradictions","description":"List of contradictions found","default":[]}},"type":"object","required":["hallucination_level","hallucination_percentage","reason","contexts","verdicts","contradictions_count","total_contexts_count","sensitivity_level"],"title":"HallucinationEvaluationResult","description":"Pydantic model for complete hallucination evaluation results."},"HallucinationLevel":{"type":"string","enum":["excellent","good","fair","poor"],"title":"HallucinationLevel","description":"Enum for the 4-level categorical hallucination scoring."},"HallucinationResult":{"properties":{"score":{"type":"number","title":"Score","description":"Hallucination score between 0.0 and 1.0"},"faithfulness_level":{"$ref":"#/components/schemas/FaithfulnessLevel","description":"Categorical faithfulness level: excellent, good, fair, or poor"},"reason":{"items":{"type":"string"},"type":"array","title":"Reason","description":"List of reasons for the score. Can be empty if no issues found."}},"type":"object","required":["score","faithfulness_level","reason"],"title":"HallucinationResult","description":"Pydantic model for hallucination evaluation results."},"HallucinationVerdictItem":{"properties":{"verdict":{"type":"string","pattern":"^(yes|no)$","title":"Verdict","description":"Verdict: 'yes' or 'no'"},"reason":{"type":"string","minLength":5,"title":"Reason","description":"Reason for the verdict"}},"type":"object","required":["verdict","reason"],"title":"HallucinationVerdictItem","description":"Pydantic model for individual hallucination verdict items."},"IllegalInputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The user input to analyze for requests related to illegal activities."},"sensitivity":{"$ref":"#/components/schemas/guardrail__illegal_guard__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["input_text"],"title":"IllegalInputRequest"},"IllegalInputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|uncertain)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'uncertain'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the legality assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text that was analyzed"},"illegal_categories":{"items":{"type":"string"},"type":"array","title":"Illegal Categories","description":"Specific categories of illegal activities detected","default":[]},"sensitivity_level":{"$ref":"#/components/schemas/guardrail__illegal_guard__SensitivityLevel","description":"Sensitivity level used for evaluation"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0},"confidence":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Confidence","description":"Confidence level in assessment (0.0-1.0)","default":0.8}},"type":"object","required":["safety_level","reason","input_text","sensitivity_level"],"title":"IllegalInputResult","description":"Pydantic model for input illegal activities detection results."},"IllegalOutputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The original user input that prompted the AI's response."},"output_text":{"type":"string","title":"Output Text","description":"The AI's response to analyze for facilitation of illegal activities."},"sensitivity":{"$ref":"#/components/schemas/guardrail__illegal_guard__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["input_text","output_text"],"title":"IllegalOutputRequest"},"IllegalOutputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|uncertain)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'uncertain'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the legality assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text"},"output_text":{"type":"string","title":"Output Text","description":"The AI output that was analyzed"},"illegal_categories":{"items":{"type":"string"},"type":"array","title":"Illegal Categories","description":"Specific categories of illegal activities detected","default":[]},"sensitivity_level":{"$ref":"#/components/schemas/guardrail__illegal_guard__SensitivityLevel","description":"Sensitivity level used for evaluation"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0},"confidence":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Confidence","description":"Confidence level in assessment (0.0-1.0)","default":0.8}},"type":"object","required":["safety_level","reason","input_text","output_text","sensitivity_level"],"title":"IllegalOutputResult","description":"Pydantic model for output illegal activities detection results."},"ModerationRequest":{"properties":{"text":{"type":"string","title":"Text","description":"The text content to be moderated."},"sensitivity":{"$ref":"#/components/schemas/opik_eval__moderation__SensitivityLevel","description":"The sensitivity level for moderation.","default":"medium"}},"type":"object","required":["text"],"title":"ModerationRequest"},"ModerationResult":{"properties":{"score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Score","description":"Safety score between 0 and 1"},"safety_level":{"$ref":"#/components/schemas/SafetyLevel","description":"Categorical safety level: excellent, good, fair, or poor"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Brief explanation of the score"},"sensitivity_level":{"$ref":"#/components/schemas/opik_eval__moderation__SensitivityLevel","description":"Sensitivity level used for evaluation"}},"type":"object","required":["score","safety_level","reason","sensitivity_level"],"title":"ModerationResult","description":"Pydantic model for moderation results with validation."},"PIILeakageEvaluationResult":{"properties":{"privacy_level":{"$ref":"#/components/schemas/PrivacyLevel","description":"Categorical privacy level: excellent, good, fair, or poor"},"privacy_percentage":{"type":"number","maximum":100.0,"minimum":0.0,"title":"Privacy Percentage","description":"Percentage of privacy violations (0.0 to 100.0)"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the privacy level"},"extracted_pii":{"items":{"type":"string"},"type":"array","title":"Extracted Pii","description":"PII statements extracted from the output"},"verdicts":{"items":{"$ref":"#/components/schemas/PIIVerdictItem"},"type":"array","title":"Verdicts","description":"Privacy violation verdicts for each statement"},"privacy_violations_count":{"type":"integer","title":"Privacy Violations Count","description":"Number of privacy violations found"},"total_statements_count":{"type":"integer","title":"Total Statements Count","description":"Total number of statements analyzed"},"sensitivity_level":{"$ref":"#/components/schemas/deepeval_eval__pii_leakage__SensitivityLevel","description":"Sensitivity level used for evaluation"}},"type":"object","required":["privacy_level","privacy_percentage","reason","extracted_pii","verdicts","privacy_violations_count","total_statements_count","sensitivity_level"],"title":"PIILeakageEvaluationResult","description":"Pydantic model for complete PII leakage evaluation results."},"PIIVerdictItem":{"properties":{"verdict":{"type":"string","pattern":"^(yes|no)$","title":"Verdict","description":"Verdict: 'yes' or 'no'"},"reason":{"type":"string","minLength":5,"title":"Reason","description":"Brief explanation of the verdict"}},"type":"object","required":["verdict","reason"],"title":"PIIVerdictItem","description":"Pydantic model for individual PII verdict items."},"PiiLeakageRequest":{"properties":{"ai_output":{"type":"string","title":"Ai Output","description":"The AI's response to be evaluated for PII leakage."},"sensitivity":{"$ref":"#/components/schemas/deepeval_eval__answer_relevancy__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["ai_output"],"title":"PiiLeakageRequest"},"PrecisionLevel":{"type":"string","enum":["excellent","good","fair","poor"],"title":"PrecisionLevel","description":"Enum for the 4-level categorical precision scoring."},"PrivacyInputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The user input to analyze for privacy violations."},"sensitivity":{"$ref":"#/components/schemas/guardrail__privacy_guard__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["input_text"],"title":"PrivacyInputRequest"},"PrivacyInputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|borderline)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'borderline'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the privacy assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text that was analyzed"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0},"sensitivity_level":{"type":"string","title":"Sensitivity Level","description":"The sensitivity level used for this assessment","default":"medium"}},"type":"object","required":["safety_level","reason","input_text"],"title":"PrivacyInputResult","description":"Pydantic model for input privacy protection detection results."},"PrivacyLevel":{"type":"string","enum":["excellent","good","fair","poor"],"title":"PrivacyLevel","description":"Enum for the 4-level categorical privacy scoring."},"PrivacyOutputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The original user input that prompted the AI's response."},"output_text":{"type":"string","title":"Output Text","description":"The AI's response to analyze for privacy violations."},"sensitivity":{"$ref":"#/components/schemas/guardrail__privacy_guard__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["input_text","output_text"],"title":"PrivacyOutputRequest"},"PrivacyOutputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|borderline)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'borderline'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the privacy assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text"},"output_text":{"type":"string","title":"Output Text","description":"The AI output that was analyzed"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0},"sensitivity_level":{"type":"string","title":"Sensitivity Level","description":"The sensitivity level used for this assessment","default":"medium"}},"type":"object","required":["safety_level","reason","input_text","output_text"],"title":"PrivacyOutputResult","description":"Pydantic model for output privacy protection detection results."},"PromptInjectionInputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The user input to analyze for prompt injection attempts."}},"type":"object","required":["input_text"],"title":"PromptInjectionInputRequest"},"PromptInjectionInputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|uncertain)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'uncertain'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the safety assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text that was analyzed"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0}},"type":"object","required":["safety_level","reason","input_text"],"title":"PromptInjectionInputResult","description":"Pydantic model for input prompt injection detection results."},"PromptInjectionOutputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The original user input that prompted the AI's response."},"output_text":{"type":"string","title":"Output Text","description":"The AI's response to analyze for successful prompt injection."}},"type":"object","required":["input_text","output_text"],"title":"PromptInjectionOutputRequest"},"PromptInjectionOutputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|uncertain)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'uncertain'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the safety assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text"},"output_text":{"type":"string","title":"Output Text","description":"The AI output that was analyzed"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0}},"type":"object","required":["safety_level","reason","input_text","output_text"],"title":"PromptInjectionOutputResult","description":"Pydantic model for output prompt injection detection results."},"RecallLevel":{"type":"string","enum":["excellent","good","fair","poor"],"title":"RecallLevel","description":"Enum for the 4-level categorical recall scoring."},"RelevancyLevel":{"type":"string","enum":["excellent","good","fair","poor"],"title":"RelevancyLevel","description":"Enum for the 4-level categorical relevancy scoring."},"SafetyLevel":{"type":"string","enum":["excellent","good","fair","poor"],"title":"SafetyLevel","description":"Enum for the 4-level categorical safety scoring."},"ToxicityEvaluationResult":{"properties":{"toxicity_level":{"$ref":"#/components/schemas/ToxicityLevel","description":"Categorical toxicity level: excellent, good, fair, or poor"},"toxicity_percentage":{"type":"number","maximum":100.0,"minimum":0.0,"title":"Toxicity Percentage","description":"Percentage of toxic content (0.0 to 100.0)"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the toxicity level"},"opinions":{"items":{"type":"string"},"type":"array","title":"Opinions","description":"Opinions extracted from the output"},"verdicts":{"items":{"$ref":"#/components/schemas/ToxicityVerdictItem"},"type":"array","title":"Verdicts","description":"Toxicity verdicts for each opinion"},"toxic_opinions_count":{"type":"integer","title":"Toxic Opinions Count","description":"Number of toxic opinions"},"total_opinions_count":{"type":"integer","title":"Total Opinions Count","description":"Total number of opinions"},"sensitivity_level":{"$ref":"#/components/schemas/deepeval_eval__toxicity__SensitivityLevel","description":"Sensitivity level used for evaluation"}},"type":"object","required":["toxicity_level","toxicity_percentage","reason","opinions","verdicts","toxic_opinions_count","total_opinions_count","sensitivity_level"],"title":"ToxicityEvaluationResult","description":"Pydantic model for complete toxicity evaluation results."},"ToxicityInputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The user input to analyze for toxicity."},"sensitivity":{"$ref":"#/components/schemas/guardrail__toxic_guard__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["input_text"],"title":"ToxicityInputRequest"},"ToxicityInputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|uncertain)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'uncertain'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the toxicity assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text that was analyzed"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0},"sensitivity_level":{"type":"string","title":"Sensitivity Level","description":"The sensitivity level used for this assessment","default":"medium"}},"type":"object","required":["safety_level","reason","input_text"],"title":"ToxicityInputResult","description":"Pydantic model for input toxicity detection results."},"ToxicityLevel":{"type":"string","enum":["excellent","good","fair","poor"],"title":"ToxicityLevel","description":"Enum for the 4-level categorical toxicity scoring."},"ToxicityOutputRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The original user input that prompted the AI's response."},"output_text":{"type":"string","title":"Output Text","description":"The AI's response to analyze for toxicity."},"sensitivity":{"$ref":"#/components/schemas/guardrail__toxic_guard__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["input_text","output_text"],"title":"ToxicityOutputRequest"},"ToxicityOutputResult":{"properties":{"safety_level":{"type":"string","pattern":"^(safe|unsafe|uncertain)$","title":"Safety Level","description":"Safety level: 'safe', 'unsafe', or 'uncertain'"},"reason":{"type":"string","minLength":10,"title":"Reason","description":"Detailed explanation of the toxicity assessment"},"input_text":{"type":"string","title":"Input Text","description":"The original input text"},"output_text":{"type":"string","title":"Output Text","description":"The AI output that was analyzed"},"risk_score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Risk Score","description":"Risk score between 0.0, 0.5 and 1.0 (higher is riskier)","default":0.0},"sensitivity_level":{"type":"string","title":"Sensitivity Level","description":"The sensitivity level used for this assessment","default":"medium"}},"type":"object","required":["safety_level","reason","input_text","output_text"],"title":"ToxicityOutputResult","description":"Pydantic model for output toxicity detection results."},"ToxicityRequest":{"properties":{"ai_output":{"type":"string","title":"Ai Output","description":"The AI's response to be evaluated for toxicity."},"sensitivity":{"$ref":"#/components/schemas/deepeval_eval__answer_relevancy__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["ai_output"],"title":"ToxicityRequest"},"ToxicityVerdictItem":{"properties":{"verdict":{"type":"string","pattern":"^(yes|no|mild)$","title":"Verdict","description":"Verdict: 'yes', 'no', or 'mild'"},"reason":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Reason","description":"Reason for the verdict (required for 'yes' and 'mild' verdicts)"}},"type":"object","required":["verdict"],"title":"ToxicityVerdictItem","description":"Pydantic model for individual toxicity verdict items."},"UsefulnessLevel":{"type":"string","enum":["excellent","good","fair","poor"],"title":"UsefulnessLevel","description":"Enum for the 4-level categorical usefulness scoring."},"UsefulnessRequest":{"properties":{"user_input":{"type":"string","title":"User Input","description":"The user's original question or prompt."},"ai_output":{"type":"string","title":"Ai Output","description":"The AI's response to be evaluated for its usefulness."}},"type":"object","required":["user_input","ai_output"],"title":"UsefulnessRequest"},"UsefulnessResult":{"properties":{"score":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Score","description":"Usefulness score between 0.0 and 1.0"},"usefulness_level":{"$ref":"#/components/schemas/UsefulnessLevel","description":"Categorical usefulness level: excellent, good, fair, or poor"},"reason":{"type":"string","minLength":20,"title":"Reason","description":"Brief explanation of the score based on evaluation criteria"}},"type":"object","required":["score","usefulness_level","reason"],"title":"UsefulnessResult","description":"Pydantic model for usefulness evaluation results with validation."},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"},"VerdictItem":{"properties":{"verdict":{"type":"string","pattern":"^(yes|no|idk)$","title":"Verdict","description":"Verdict: 'yes', 'no', or 'idk'"},"reason":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Reason","description":"Reason for the verdict (required only for 'no' verdicts)"}},"type":"object","required":["verdict"],"title":"VerdictItem","description":"Pydantic model for individual verdict items."},"deepeval_eval__answer_relevancy__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"deepeval_eval__deepeval_api__HallucinationRequest":{"properties":{"actual_output":{"type":"string","title":"Actual Output","description":"The AI's response to be evaluated for hallucinations."},"contexts":{"items":{"type":"string"},"type":"array","title":"Contexts","description":"A list of context strings to verify the output against."},"user_input":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"User Input","description":"The user's original question for contextual evaluation."},"sensitivity":{"$ref":"#/components/schemas/deepeval_eval__answer_relevancy__SensitivityLevel","description":"The sensitivity level for the evaluation.","default":"medium"}},"type":"object","required":["actual_output","contexts"],"title":"HallucinationRequest"},"deepeval_eval__faithfulness__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"deepeval_eval__hallucination__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"deepeval_eval__pii_leakage__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"deepeval_eval__toxicity__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"guardrail__cyber_security_guard__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"guardrail__illegal_guard__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels in illegal activities detection."},"guardrail__privacy_guard__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for privacy detection sensitivity levels."},"guardrail__toxic_guard__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for toxicity detection sensitivity levels."},"opik_eval__answer_relevance__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"opik_eval__context_precision__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"opik_eval__context_recall__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"opik_eval__moderation__SensitivityLevel":{"type":"string","enum":["low","medium","high"],"title":"SensitivityLevel","description":"Enum for sensitivity levels."},"opik_eval__opic_eval_api__HallucinationRequest":{"properties":{"input_text":{"type":"string","title":"Input Text","description":"The original input/question (for context only)."},"context":{"type":"string","title":"Context","description":"The reference context to compare against."},"output":{"type":"string","title":"Output","description":"The AI-generated output to evaluate."}},"type":"object","required":["input_text","context","output"],"title":"HallucinationRequest"}}}}